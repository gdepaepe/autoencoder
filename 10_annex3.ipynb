{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c62fca-6910-4e57-8245-d3bd9df547ec",
   "metadata": {},
   "source": [
    "# 10. Annex 3: Use the model on a climate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dcbdb1-accf-4c2a-809e-83afa2eebf9e",
   "metadata": {},
   "source": [
    "## 10.1 Load CNRM-ESM2 data\n",
    "CMIP6 climate (earth system model) projections\n",
    "\n",
    "CNRM-ESM2 - Climate data downloaded from ESGF https://aims2.llnl.gov/metagrid/search/?project=CMIP6\n",
    "\n",
    "- Sea level pressure [Pa]: psl_day_CNRM-ESM2-1_ssp585_r1i1p1f2_gr_20150101-21001231.nc \n",
    "- 500 hPa geopotential height [m]: zg500_AERday_CNRM-ESM2-1_ssp585_r1i1p1f2_gr_20150101-21001231.nc\n",
    "\n",
    "References: http://www.umr-cnrm.fr/cmip6/references https://explore.es-doc.org/cmip6/further-info?target=CMIP6.CNRM-CERFACS.CNRM-ESM2-1.ssp585.none.r1i1p1f2 \n",
    "\n",
    "The 256x128 grid points are covering the whole earth for 31411 days (1/1/2015 31/12/2100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0383ec41-14ab-4a59-91d1-6c48bd1e088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['lat', 'lon', 'time', 'time_bounds', 'psl'])\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 psl(time, lat, lon)\n",
      "    long_name: Sea Level Pressure\n",
      "    units: Pa\n",
      "    online_operation: average\n",
      "    cell_methods: area: time: mean\n",
      "    interval_operation: 900 s\n",
      "    interval_write: 1 d\n",
      "    _FillValue: 1e+20\n",
      "    missing_value: 1e+20\n",
      "    coordinates: \n",
      "    description: Sea Level Pressure\n",
      "    history: none\n",
      "    cell_measures: area: areacella\n",
      "    standard_name: air_pressure_at_mean_sea_level\n",
      "unlimited dimensions: time\n",
      "current shape = (31411, 128, 256)\n",
      "filling on\n",
      "dict_keys(['lat', 'lon', 'plev', 'time', 'time_bounds', 'zg500'])\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 zg500(time, lat, lon)\n",
      "    online_operation: average\n",
      "    cell_methods: area: time: mean\n",
      "    interval_operation: 900 s\n",
      "    interval_write: 1 d\n",
      "    _FillValue: 1e+20\n",
      "    missing_value: 1e+20\n",
      "    coordinates: plev\n",
      "    standard_name: geopotential_height\n",
      "    description: geopotential height on the 500 hPa surface\n",
      "    long_name: Geopotential Height at 500 hPa\n",
      "    history: none\n",
      "    units: m\n",
      "    cell_measures: area: areacella\n",
      "unlimited dimensions: time\n",
      "current shape = (31411, 128, 256)\n",
      "filling on\n"
     ]
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "for dataset in [\"psl\",\"zg500\"]:\n",
    "    df = nc.Dataset(\"data/ESM2_\" + dataset + \".nc\",'r')\n",
    "    print(df.variables.keys())\n",
    "    print(df[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ddea7d-78b6-465c-8156-920208808621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31411, 32, 64)\n",
      "(31411, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "zone=np.array([70.,25.,-58.,33.])\n",
    "for dataset in [\"psl\",\"zg500\"]:\n",
    "    df = nc.Dataset(\"data/ESM2_\" + dataset + \".nc\",'r')\n",
    "    data = np.array(df[dataset][:,::-1,:])  # making it N to S\n",
    "    east = np.array(data[:,int((90-zone[0])*128/180):int((90-zone[1])*128/180),0:int(zone[3]*256/360)])  # 70->25N, 0->33E\n",
    "    west = np.array(data[:,int((90-zone[0])*128/180):int((90-zone[1])*128/180),int(zone[2]*256/360):])   # 70->25N, 58W->0\n",
    "    data = np.concatenate((west,east),axis=2)\n",
    "    print(data.shape)\n",
    "    np.save(\"data/climate_\" + dataset + \".npy\", data)\n",
    "np.save(\"data/climate_zone.npy\", zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53984a3a-aac8-49bd-8bd4-bc402f729985",
   "metadata": {},
   "source": [
    "We scale with the same values of the ERA-20C dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0931dace-09a7-4dd4-9b2f-3396d5aa0790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31411, 32, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "msl = np.load(\"data/climate_psl.npy\")\n",
    "z500 = np.load(\"data/climate_zg500.npy\")\n",
    "# scale data so that 99,99% is in [0,1]\n",
    "scale = np.array([[94000,107000],[43000./9.81,58000./9.81]])\n",
    "msl = (msl - scale[0,0]) / (scale[0,1] - scale[0,0])\n",
    "z500 = (z500 - scale[1,0]) / (scale[1,1] - scale[1,0])\n",
    "data = np.zeros((msl.shape[0],msl.shape[1],msl.shape[2],2))\n",
    "data[:,:,:,0] = msl\n",
    "data[:,:,:,1] = z500\n",
    "print(data.shape)\n",
    "np.save(\"data/climate.npy\", data)\n",
    "np.save(\"data/climate_scale.npy\", scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a26ff546-7ed0-4d50-804d-e223b920bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31411 days:  2015 1 1  ->  2100 12 31\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "base = datetime.datetime.strptime(\"01-01-2015\", \"%d-%m-%Y\")\n",
    "dates = [(base + datetime.timedelta(days=x)).strftime(\"%Y %-m %-d\") for x in range(msl.shape[0])]\n",
    "np.save(\"data/climate_dates.npy\", dates)\n",
    "print(len(dates),\"days: \",dates[0],\" -> \", dates[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65254d16-e81b-40de-97d8-3c0cc9867b3e",
   "metadata": {},
   "source": [
    "## 10.2 Does the ERA-20C model also work on the climate dataset?\n",
    "We load the ERA-20C autoencoder. Does it also work on the climate dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93ebfcfa-5ebb-471a-9127-524f6f5824b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0009813802316784859\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "file=\"data/climate.npy\"\n",
    "x = np.load(file)\n",
    "autoencoder = load_model(\"data/autoencoder.h5\")\n",
    "score = autoencoder.evaluate(x, x, verbose=0)\n",
    "print('Climate loss:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9695dbb-d0d0-433e-8651-d9072d6a9802",
   "metadata": {},
   "source": [
    "Yes it does! Let's use it to compress the climate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "222ec14c-890a-48a8-b9f9-7c12e5fb4dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "compress = load_model(\"data/compress.h5\")\n",
    "x_compress = compress.predict(x)\n",
    "np.save(\"data/climate_compressed.npy\", x_compress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "060be69a-d60a-48ee-886e-7eb8d4e87f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = np.load(\"data/climate.npy\")\n",
    "compressed = np.load(\"data/climate_compressed.npy\")\n",
    "dates = np.load(\"data/climate_dates.npy\")\n",
    "sample_size = 100\n",
    "grid_points = climate.shape[1] * climate.shape[2]\n",
    "grid_sqrt = np.sqrt(grid_points) \n",
    "rand_indices = np.random.randint(climate.shape[0],size=sample_size)\n",
    "corr =  np.zeros(sample_size)\n",
    "corr_msl =  np.zeros(sample_size)\n",
    "corr_z500 =  np.zeros(sample_size)\n",
    "for i in range(sample_size):\n",
    "    date_index = rand_indices[i]\n",
    "    compressed_ref = compressed[date_index]\n",
    "    climate_ref = climate[date_index]\n",
    "    msl_ref = msl[date_index]\n",
    "    z500_ref = z500[date_index]\n",
    "\n",
    "    # initialize arrays\n",
    "    compressed_dist = np.zeros(dates.shape[0])\n",
    "    msl_dist = np.zeros(dates.shape[0])\n",
    "    z500_dist = np.zeros(dates.shape[0])\n",
    "    climate_dist = np.zeros(dates.shape[0])\n",
    "\n",
    "    # calculate distances\n",
    "    for j in range(dates.shape[0]):\n",
    "        compressed_dist[j] = np.linalg.norm(compressed[j]-compressed_ref)\n",
    "        climate_dist[j] = np.linalg.norm(climate[j]-climate_ref)\n",
    "        msl_dist[j] = np.linalg.norm(msl[j]-msl_ref) / grid_sqrt\n",
    "        z500_dist[j] = np.linalg.norm(z500[j]-z500_ref) / grid_sqrt\n",
    "        \n",
    "    # calculate correlation coefficients\n",
    "    corr[i] = np.corrcoef(compressed_dist,climate_dist)[0,1]\n",
    "    corr_msl[i] = np.corrcoef(compressed_dist,msl_dist)[0,1]\n",
    "    corr_z500[i] = np.corrcoef(compressed_dist,z500_dist)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33f90a80-55ca-4f3c-b264-b8c8456fb850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>corr_msl</th>\n",
       "      <th>corr_z500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.715</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corr  corr_msl  corr_z500\n",
       "count 100.000   100.000    100.000\n",
       "mean    0.946     0.523      0.975\n",
       "std     0.057     0.320      0.022\n",
       "min     0.715    -0.280      0.854\n",
       "25%     0.937     0.188      0.968\n",
       "50%     0.966     0.623      0.983\n",
       "75%     0.982     0.808      0.990\n",
       "max     0.990     0.889      0.995"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd_corr = pd.DataFrame(corr, columns=['corr'])\n",
    "pd_corr['corr_msl'] = pd.DataFrame(corr_msl, columns=['corr'])\n",
    "pd_corr['corr_z500'] = pd.DataFrame(corr_z500, columns=['corr'])\n",
    "pd_corr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bd40b1f-19e0-4070-b22f-3e911d41842b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corr        0.006\n",
       "corr_msl    0.032\n",
       "corr_z500   0.002\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_corr.std()/np.sqrt(sample_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d4f05-9e8f-4ad0-860c-80ee2d0839b1",
   "metadata": {},
   "source": [
    "## 10.2 Does the ERA-20C model also work for another zone?\n",
    "Let's take the US and North Pacific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe381c02-b52e-44a3-9b00-1556101d9ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31411, 32, 64)\n",
      "(31411, 32, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "zone=np.array([70.,25.,-160.,-70.])\n",
    "for dataset in [\"psl\",\"zg500\"]:\n",
    "    df = nc.Dataset(\"data/ESM2_\" + dataset + \".nc\",'r')\n",
    "    data = np.array(df[dataset][:,::-1,:])  # making it N to S\n",
    "    data = np.array(data[:,int((90-zone[0])*128/180):int((90-zone[1])*128/180),int(zone[2]*256/360):int(zone[3]*256/360)])   # 70->25N, -160->-70W->0\n",
    "    print(data.shape)\n",
    "    np.save(\"data/climate_US_\" + dataset + \".npy\", data)\n",
    "np.save(\"data/climate_US__zone.npy\", zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e4b41e-e365-4fe8-8b34-ff7f564f18de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31411, 32, 64, 2)\n"
     ]
    }
   ],
   "source": [
    "msl = np.load(\"data/climate_US_psl.npy\")\n",
    "z500 = np.load(\"data/climate_US_zg500.npy\")\n",
    "# scale data so that 99,99% is in [0,1]\n",
    "scale = np.array([[94000,107000],[43000./9.81,58000./9.81]])\n",
    "msl = (msl - scale[0,0]) / (scale[0,1] - scale[0,0])\n",
    "z500 = (z500 - scale[1,0]) / (scale[1,1] - scale[1,0])\n",
    "data = np.zeros((msl.shape[0],msl.shape[1],msl.shape[2],2))\n",
    "data[:,:,:,0] = msl\n",
    "data[:,:,:,1] = z500\n",
    "print(data.shape)\n",
    "np.save(\"data/climate_US.npy\", data)\n",
    "np.save(\"data/climate_scale.npy\", scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f506d0fb-5cd1-4020-98fd-4fba40cfc812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate US loss: 0.0015483705792576075\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "file=\"data/climate_US.npy\"\n",
    "x = np.load(file)\n",
    "autoencoder = load_model(\"data/autoencoder.h5\")\n",
    "score = autoencoder.evaluate(x, x, verbose=0)\n",
    "print('Climate US loss:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fc37c8-cc88-4b1c-b238-23660b4dd97f",
   "metadata": {},
   "source": [
    "Not as good as the same zone, but also not that bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dc2270d-5046-4575-9002-caef069cc8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "compress = load_model(\"data/compress.h5\")\n",
    "x_compress = compress.predict(x)\n",
    "np.save(\"data/climate_US_compressed.npy\", x_compress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "231cfdb0-6712-4f35-ad1a-789bb761e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = np.load(\"data/climate_US.npy\")\n",
    "compressed = np.load(\"data/climate_US_compressed.npy\")\n",
    "dates = np.load(\"data/climate_dates.npy\")\n",
    "sample_size = 100\n",
    "grid_points = climate.shape[1] * climate.shape[2]\n",
    "grid_sqrt = np.sqrt(grid_points) \n",
    "rand_indices = np.random.randint(climate.shape[0],size=sample_size)\n",
    "corr =  np.zeros(sample_size)\n",
    "corr_msl =  np.zeros(sample_size)\n",
    "corr_z500 =  np.zeros(sample_size)\n",
    "for i in range(sample_size):\n",
    "    date_index = rand_indices[i]\n",
    "    compressed_ref = compressed[date_index]\n",
    "    climate_ref = climate[date_index]\n",
    "    msl_ref = msl[date_index]\n",
    "    z500_ref = z500[date_index]\n",
    "\n",
    "    # initialize arrays\n",
    "    compressed_dist = np.zeros(dates.shape[0])\n",
    "    msl_dist = np.zeros(dates.shape[0])\n",
    "    z500_dist = np.zeros(dates.shape[0])\n",
    "    climate_dist = np.zeros(dates.shape[0])\n",
    "\n",
    "    # calculate distances\n",
    "    for j in range(dates.shape[0]):\n",
    "        compressed_dist[j] = np.linalg.norm(compressed[j]-compressed_ref)\n",
    "        climate_dist[j] = np.linalg.norm(climate[j]-climate_ref)\n",
    "        msl_dist[j] = np.linalg.norm(msl[j]-msl_ref) / grid_sqrt\n",
    "        z500_dist[j] = np.linalg.norm(z500[j]-z500_ref) / grid_sqrt\n",
    "        \n",
    "    # calculate correlation coefficients\n",
    "    corr[i] = np.corrcoef(compressed_dist,climate_dist)[0,1]\n",
    "    corr_msl[i] = np.corrcoef(compressed_dist,msl_dist)[0,1]\n",
    "    corr_z500[i] = np.corrcoef(compressed_dist,z500_dist)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebdd256f-e3cb-4aaf-b880-f53f6516f20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>corr_msl</th>\n",
       "      <th>corr_z500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.769</td>\n",
       "      <td>-0.463</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.935</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         corr  corr_msl  corr_z500\n",
       "count 100.000   100.000    100.000\n",
       "mean    0.950     0.305      0.968\n",
       "std     0.050     0.366      0.029\n",
       "min     0.769    -0.463      0.868\n",
       "25%     0.935    -0.013      0.962\n",
       "50%     0.971     0.343      0.980\n",
       "75%     0.986     0.672      0.987\n",
       "max     0.993     0.775      0.994"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd_corr = pd.DataFrame(corr, columns=['corr'])\n",
    "pd_corr['corr_msl'] = pd.DataFrame(corr_msl, columns=['corr'])\n",
    "pd_corr['corr_z500'] = pd.DataFrame(corr_z500, columns=['corr'])\n",
    "pd_corr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e2c7bd6-38ab-41f6-bf57-ef2e43a59231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corr        0.005\n",
       "corr_msl    0.037\n",
       "corr_z500   0.003\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_corr.std()/np.sqrt(sample_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfefa6-d390-488e-92e2-11a17bb40e08",
   "metadata": {},
   "source": [
    "The results suggest that it would be possible to build a zone independent compression model.\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
