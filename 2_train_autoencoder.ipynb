{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8ed61c-e1d7-4cfc-ac45-da00e433dbfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Train autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f4599-52ba-4d46-ba2b-df0747223db6",
   "metadata": {},
   "source": [
    "## 2.1 Set environment\n",
    "For building the neural network, Keras is used as an interface to TensorFlow. Tensorflow [1] (https://www.tensorflow.org/) is an open-source library for building neural network developed by Google. Keras [3] (https://keras.io/) is an open-source python library providing a more high level and user-friendly interface to the Tensorflow backend. \n",
    "We load the Keras modules and set the location of the data file in the file variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a30e12-52a1-4b7b-8a9b-b8cede6cd054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 17:56:05.291454: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-25 17:56:05.291603: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import save_model, load_model\n",
    "from keras.callbacks import TensorBoard\n",
    "from isoplot import isoplot\n",
    "# Set location of data file\n",
    "file=\"data/era20c.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3ec3d-e387-4da5-9a6c-73942edbf2ed",
   "metadata": {},
   "source": [
    "## 2.2 Create train, validate and test datasets\n",
    "After randomizing the order of the data, the dataset is split in 3 parts:\n",
    "- a train dataset for training the NN with 90% of the data\n",
    "- a validation dataset, used to validate the model during training, with 5% of the data\n",
    "- a test dataset, which is not used during training, to evaluate the model, with 5% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15cb92-427f-408a-bffa-52c1f6dd97de",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/era20c.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# N is the size of the test and validation dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m data[i]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py:407\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    408\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/era20c.npy'"
     ]
    }
   ],
   "source": [
    "# N is the size of the test and validation dataset\n",
    "N = 2000\n",
    "data = np.load(file)\n",
    "i = np.argsort(np.random.random(data.shape[0]))\n",
    "data = data[i]\n",
    "test = data[:N//2]\n",
    "validate = data[N//2:N]\n",
    "train = data[N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0d447-d060-4a5f-afcb-9320ff29c914",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3 Architecture of the neural network\n",
    "We will use a convolute autoencoder neural network to be able to compress our section of the ERA-20C dataset with the MSP and Z500 data. The first half of the autoencoder is the encoder. The convolute layers are based on a 3x3 kernel, and so have 9 parameters to learn. Our input values are maps of 32x64 with 2 channels: MSP and Z500. The first convolute layer keeps the spatial dimension, but increases the number of channels to 32. So this layer has 2x32 kernels, plus 32 biases, giving in total 608 parameters to learn. Convolutional layers are followed by 2x2 pooling layers, which are taking the maximum of the 4 grid points. They reduce the spatial resolution by a factor 2. We use the convolute/pooling combination 3 times (going from 32x64 to 4x8). We also reduced the number of channels to one. This give a total dimension reduction factor of 128 (from 4096 to 32).\n",
    "\n",
    "The decoding part is a \"mirror\" of the encoding part, using nearest neighbor upsampling layers instead of pooling layers. So the spatial resolution is multiplied by 2 for each upsampling layer. The model will be trained so that after compressing and decoding, the output is as close as possible to input. This is done by minimizing the mean square error (MSE) loss function over all gridpoints and channels between the output and input. The Adam optimizer is used, which is variant of the stochastic gradient descent algorithm. Rectified Linear Unit (ReLu) activation functions are used, except for the one preceding the MSE operator (which uses a sigmoid activation function). Tuning has been done on the hyperparameters (type and numbers of layers, dimensions, channels, activation functions,...), but further improvement can probably be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd73399-290f-4d67-8b1b-8faa36633355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 64, 2)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 64, 32)        608       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 32, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 32, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 16, 16)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 16, 8)          1160      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 8, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 8, 1)           73        \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 8, 8)           80        \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 8, 16, 8)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 16, 16)         1168      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 16, 32, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 32, 32)        4640      \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 32, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 64, 2)         578       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,931\n",
      "Trainable params: 12,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 09:44:22.397873: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Encoder (32,64,2) - > (4,8,1)\n",
    "input = keras.Input(shape=(32, 64, 2))\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = layers.Conv2D(1, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "# Decoder (4,8,1) -> (32,64,2)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu',padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(2, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='MSE')\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f9736-d549-4774-92c4-b791b642cac0",
   "metadata": {},
   "source": [
    "## 2.4 Start tensorboard\n",
    "For following up the training the tensorboard is started. To access tensorboard, surf with your browser to the IP address of your machine with port number 6006."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c8d39f-9eff-4f86-a7b7-29da781e8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/bin/bash -c tensorboard --host 0.0.0.0 --logdir=/tmp/autoencoder 2> /dev/null &\n",
    "#firefox 127.0.0.1:6006 &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f18fb2-4e84-432b-8aea-ff7222140249",
   "metadata": {},
   "source": [
    "## 2.5 Train the model\n",
    "Here the model is trained. The epoch number is specifying how many cycles over the complete dataset are done. The batch size specifies after how many samples the parameters are updated by the back propagation algorithm. Dependent on the computer power, this step can take a while. Afterwards the model is saved in a hdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7b533a-c802-4fec-8218-abb785a7f94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "151/151 [==============================] - 85s 554ms/step - loss: 0.0096 - val_loss: 0.0034\n",
      "Epoch 2/30\n",
      "151/151 [==============================] - 82s 543ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 3/30\n",
      "151/151 [==============================] - 84s 556ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 4/30\n",
      "151/151 [==============================] - 82s 546ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 5/30\n",
      "151/151 [==============================] - 83s 549ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "151/151 [==============================] - 83s 549ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/30\n",
      "151/151 [==============================] - 84s 559ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 8/30\n",
      "151/151 [==============================] - 83s 553ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 9/30\n",
      "151/151 [==============================] - 82s 543ms/step - loss: 9.8796e-04 - val_loss: 9.5186e-04\n",
      "Epoch 10/30\n",
      "151/151 [==============================] - 83s 549ms/step - loss: 9.6082e-04 - val_loss: 9.5324e-04\n",
      "Epoch 11/30\n",
      "151/151 [==============================] - 83s 548ms/step - loss: 9.3249e-04 - val_loss: 9.0930e-04\n",
      "Epoch 12/30\n",
      "151/151 [==============================] - 85s 563ms/step - loss: 9.1702e-04 - val_loss: 9.0095e-04\n",
      "Epoch 13/30\n",
      "151/151 [==============================] - 82s 543ms/step - loss: 9.0025e-04 - val_loss: 8.7247e-04\n",
      "Epoch 14/30\n",
      "151/151 [==============================] - 83s 549ms/step - loss: 8.7914e-04 - val_loss: 8.9539e-04\n",
      "Epoch 15/30\n",
      "151/151 [==============================] - 82s 541ms/step - loss: 8.6976e-04 - val_loss: 8.4777e-04\n",
      "Epoch 16/30\n",
      "151/151 [==============================] - 82s 540ms/step - loss: 8.5210e-04 - val_loss: 8.6560e-04\n",
      "Epoch 17/30\n",
      "151/151 [==============================] - 83s 547ms/step - loss: 8.4504e-04 - val_loss: 8.3985e-04\n",
      "Epoch 18/30\n",
      "151/151 [==============================] - 82s 544ms/step - loss: 8.3560e-04 - val_loss: 8.4905e-04\n",
      "Epoch 19/30\n",
      "151/151 [==============================] - 82s 541ms/step - loss: 8.1760e-04 - val_loss: 8.1008e-04\n",
      "Epoch 20/30\n",
      "151/151 [==============================] - 83s 548ms/step - loss: 8.1713e-04 - val_loss: 7.9595e-04\n",
      "Epoch 21/30\n",
      "151/151 [==============================] - 84s 555ms/step - loss: 8.0629e-04 - val_loss: 8.0473e-04\n",
      "Epoch 22/30\n",
      "151/151 [==============================] - 84s 553ms/step - loss: 7.9648e-04 - val_loss: 7.8327e-04\n",
      "Epoch 23/30\n",
      "151/151 [==============================] - 83s 551ms/step - loss: 7.9307e-04 - val_loss: 7.7276e-04\n",
      "Epoch 24/30\n",
      "151/151 [==============================] - 82s 544ms/step - loss: 7.8493e-04 - val_loss: 7.6723e-04\n",
      "Epoch 25/30\n",
      "151/151 [==============================] - 83s 550ms/step - loss: 7.7533e-04 - val_loss: 7.7247e-04\n",
      "Epoch 26/30\n",
      "151/151 [==============================] - 83s 547ms/step - loss: 7.7284e-04 - val_loss: 7.5876e-04\n",
      "Epoch 27/30\n",
      "151/151 [==============================] - 83s 549ms/step - loss: 7.7258e-04 - val_loss: 7.5194e-04\n",
      "Epoch 28/30\n",
      "151/151 [==============================] - 84s 554ms/step - loss: 7.6098e-04 - val_loss: 7.8368e-04\n",
      "Epoch 29/30\n",
      "151/151 [==============================] - 82s 542ms/step - loss: 7.5612e-04 - val_loss: 7.4999e-04\n",
      "Epoch 30/30\n",
      "151/151 [==============================] - 83s 553ms/step - loss: 7.5752e-04 - val_loss: 7.5355e-04\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(train, train,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(validate, validate),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
    "\n",
    "autoencoder.save(\"data/autoencoder.h5\")\n",
    "#save_model(autoencoder,\"model2\")\n",
    "#autoencoder.save_weights(\"data/weights2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f820dd4-63f5-4b74-a529-feb8c387dcf7",
   "metadata": {},
   "source": [
    "## 2.6 Evaluate the model\n",
    "Evaluating the model with the test dataset, which is not used during training, gives us the average MSE between input and output. Keep in mind that the dataset is scaled towards the [0,1] interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69404bd3-6da7-42b0-8ec7-300501b55996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0007648785831406713\n"
     ]
    }
   ],
   "source": [
    "score = autoencoder.evaluate(test, test, verbose=0)\n",
    "print('Test loss:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d07936-2fd5-4858-9710-8203e74a2e66",
   "metadata": {},
   "source": [
    "## 2.7 Compare the isoplots \n",
    "Below the input (the original MSL/Z500 data) and output (after compression and decoding) is compared visually by plotting the contour maps. A date can be chosen by the date parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcce01f3-9d07-4df3-89f0-70c80027f8fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1990 1 25\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/autoencoder.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      7\u001b[0m dates \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/dates.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# set date \"%Y %-m %-d\"\n",
    "date = \"1990 1 25\"\n",
    "\n",
    "# load data\n",
    "autoencoder = load_model(\"data/autoencoder.h5\")\n",
    "x = np.load(file)\n",
    "dates = np.load(\"data/dates.npy\")\n",
    "zone = np.load(\"data/zone.npy\")\n",
    "scale = np.load(\"data/scale.npy\")\n",
    "date_index = np.where(dates == date)\n",
    "x_in = x[date_index]\n",
    "\n",
    "# compare output with input\n",
    "x_out = autoencoder.predict(x_in) \n",
    "isoplot(x_in[0,:,:,0],x_out[0,:,:,0],\"era20c \"+date,\"after (de)compression\",zone,scale[0])\n",
    "isoplot(x_in[0,:,:,1],x_out[0,:,:,1],\"era20c \"+date,\"after (de)compression\",zone,scale[1]*10,\"Z500 [dm**2/s**2]\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
